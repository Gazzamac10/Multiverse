{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car owners now have plenty of options for selling their car with one option being an online market place. Cars2u is one such website and to help potential customers they would like you to build a model that will estimate the selling price. \n",
    "\n",
    "Explore the data below (cleaning where necessary) and build a model that predicts sell price. Create new features if you feel this is appropriate. Once you have a model you are satisfied with, write a report that explains to a non-technical stakeholders (e.g. customer) how the model works and how reliable it is.      \n",
    "\n",
    "<a href='https://www.kaggle.com/datasets/nehalbirla/vehicle-dataset-from-cardekho'>Documentation.</a> This dataset is from 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KSB's\n",
    "Key KSBs you can evidence when writing a regression project:\n",
    "K13 and 14\n",
    "S10,11 and an aspect of S13\n",
    "[Portfolio Tracker](https://applied.multiverse.io/pluginfile.php/46450/mod_label/intro/Portfolio%20Tracker%202.0.xlsx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=pd.read_csv('car_details.csv')\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for context price is in indian rupees ~ 100 per £\n",
    "#could convert with something like cars['selling_price'] = cars['selling_price']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cars.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using DF.describe() is an easy way of getting descriptive statistics on your data set. Broadly discussing the importance of statistics to analysis meets part of **K13**. Defining descriptive analytics and describing the benefit of you using them in your project or broadly in your role meets part of **K14**. Applying descriptive statistics for exploratory data analysis meets part of **S10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=cars)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cars.selling_price)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxplots are a great way of identifying outliers. Once identified you can justify choices around reatining outliers or removing them to some extent. Demonstrating outlier detection can partial hit S13\n",
    "\n",
    "There are significant outliers which are heavily skewing the data (which will affect results). Combining this with the fact most owners won't be selling cars >1500000 we should remove anything bigger.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars=cars[cars['selling_price']<1500000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cars.selling_price, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could do normality tests if you wish here depending on your data- see module 8 workshop 3 - this would give you the oppoutunity to describe and demonstrate inferential stats (aspects of **S10** and **K13**) but there will be oppourtunites later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.owner.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['not_new']=cars.owner.apply(lambda x: True if x!='First Owner' else False)\n",
    "\n",
    "# Due to class imbalanace it makes sense to differentiate between first owner and not instead of dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Class imbalance intro](https://machinelearningmastery.com/what-is-imbalanced-classification/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.seller_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['seller_individual']=cars.seller_type.apply(lambda x: True if x=='Individual' else False) \n",
    "\n",
    "# Because of the class imbalance it makes sense to differentiate between individual and not as opposed to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.fuel.value_counts()\n",
    "# CNG, LPG and Electric won't make much impact on our model due to low numbers so will group as 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['fuel']=cars.fuel.apply(lambda x: 'Other' if x in ['CNG','LPG','Electric'] else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.transmission.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_dummy=pd.get_dummies(cars,columns=['fuel','transmission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_dummy.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot not that valuable on dummy data. Generally Pairplot can aid in EDA/variable selection\n",
    "#sns.pairplot(cars_dummy.select_dtypes(include=[np.number]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(cars_dummy.corr(), annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you aren't intending to run the OLS model from stats models you could run individual correlation tests (pearson's or spearman's - Module 8 workshop 3) to run hypothesis tests (The P-value is the probability that you would have found the current result if the correlation coefficient were in fact zero (null hypothesis). If this probability is lower than the conventional 5% the correlation coefficient is called statistically significant. If not statistically significant then this independent variable shouldn't be included in the model. aspects of **K13** and **S10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carX=cars_dummy[['km_driven','not_new','fuel_Petrol', 'fuel_Other', 'transmission_Manual']]\n",
    "cary=cars_dummy['selling_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(carX,cary, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carlm=LinearRegression()\n",
    "carlm.fit(X_train.values,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val=cross_val_score(carlm,carX,cary,cv=5)\n",
    "preds=carlm.predict(X_test)\n",
    "print('Train score: '+str(carlm.score(X_train,y_train)))\n",
    "print('Test score: '+str(carlm.score(X_test,y_test)))\n",
    "print('Cross-val score: '+str(cross_val.mean()))\n",
    "print('MAE: '+str(mean_absolute_error(preds,y_test)))\n",
    "print('RMSE: '+str(np.sqrt(mean_squared_error(preds,y_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metrics suggest that about 34% of the difference in sale prices can be explained by this model. Not a huge amount, but considering that much of car sales comes by bartering this isn't too unexpected. \n",
    "\n",
    "The error shows that on average a prediction is off by ~ ₹200000.\n",
    "\n",
    "Overall this does make the model somewhat unreliable, but does provide a starting point based off the features provided with ₹200000 of room for negotiation.\n",
    "\n",
    "Once you have built a model and have metrics to evaluate it you can then add/withdraw/change independent variables in a new instance of the model and compare to optimise \n",
    "\n",
    "**S11** \n",
    "\n",
    "Comparing train and test scores (also cross val scores) is a technique for checking for your model overfitting\n",
    "\n",
    "Rsquared, MAE and RMSE are all metrics that can be used to aid in evaluating model perfomance (interpret them first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effect_df=pd.DataFrame(carlm.coef_,index=X_train.columns,columns=['Effect']).sort_values(by='Effect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(effect_df)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "plt.barh(effect_df.index, effect_df['Effect'])\n",
    "plt.show()\n",
    "print(f'The intercept from our model is: {carlm.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factors that affect sale price the most are the fuel type and transmission. This model adds around ₹250000 to the predicted selling price of a car which uses diesel compared to petrol or 'other' fuel type. \n",
    "\n",
    "A manual transmission loses ₹288310 off its predicted sale price compared to automatic.\n",
    "\n",
    "For every 1km driven, the predicted price goes down by ₹1.66.\n",
    "\n",
    "Intercept is y when all x values = 0. Intercept is the value estimate from our model of a car which is new (first owner) 0km on the clock, diesel engine with automatic transmission.\n",
    "\n",
    "**Interpreting your model output is an important aspect of S11**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you then use the .predict() function in context you can use this as a jumping off point / in the results define and evaluate predictive and perscriptive analytics **K14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example code\n",
    "New_values = [[50000,1,1,0,1]]\n",
    "carlm.predict(New_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate/Additional Method - OLS Stats models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carX\n",
    "#np.asarray(carX)\n",
    "#needs to be numeric for OLS so use asarray above or astypefloat below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carX.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using statsmodels returns a p-value on our variables \n",
    "# as such prior to running the model we should lay out our null and alternate hypotheses and set put our significance lever:\n",
    "# Null: The two datasets are not significantly correlated\n",
    "# Alternate: The two datasets are significantly correlated\n",
    "# alpha = 0.05\n",
    "\n",
    "carX = sm.add_constant(carX)\n",
    "model= sm.OLS(cary,carX.astype(float), hasconst=True) \n",
    "\n",
    "res=model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If using OLS from stats models instead of SKLearn remember to interpret the model outputs (intercept/coefficients)\n",
    "\n",
    "P values lower than 0.05 signifcance level as such we can reject the null hypothesis and say there is a statistically significant correlation between our independent variables and our dependant variable and it makes sense to retain these independent variables in our model. Aspects of **K13** and **S10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is extra rigorous. I haven't seen this in a portfolio before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res.resid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your residuals are normal, it means that your assumption is valid and model inference (confidence intervals, model predictions) should also be valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
